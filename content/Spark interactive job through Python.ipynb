{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import gcp\n",
    "import gcp._context\n",
    "import gcp._util\n",
    "\n",
    "_ENDPOINT = 'https://test-dataproc.sandbox.googleapis.com'\n",
    "\n",
    "def jobs_list(context):\n",
    "    print _ENDPOINT\n",
    "    url = _ENDPOINT + '/v1beta1/projects/' + context.project_id + '/jobs/'\n",
    "    print url\n",
    "    return gcp._util.Http.request(url, '', credentials=context.credentials)\n",
    "  \n",
    "def jobs_submit(context):\n",
    "    url = _ENDPOINT + '/v1beta1/projects/' + context.project_id + '/jobs:submit'\n",
    "    \n",
    "    return gcp._util.Http.request(url, '', credentials=context.credentials)  \n",
    "  \n",
    "_JOBS_PATH = '/projects/%s/jobs/%s'\n",
    "  \n",
    "def jobs_get(job_id, context):\n",
    "  \"\"\"Issues a request to retrieve information about a job.\n",
    "  Args:\n",
    "    job_id: the id of the job\n",
    "    project_id: the project id to use to fetch the results; use None for the default project.\n",
    "  Returns:\n",
    "    A parsed result object.\n",
    "  Raises:\n",
    "    Exception if there is an error performing the operation.\n",
    "  \"\"\"\n",
    "  url = _ENDPOINT + '/v1beta1/projects/'+ context.project_id + '/jobs/' + job_id\n",
    "  \n",
    "  return gcp._util.Http.request(url, '', credentials=context.credentials)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://test-dataproc.sandbox.googleapis.com\n",
      "https://test-dataproc.sandbox.googleapis.com/v1beta1/projects/datalab-spark/jobs/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'jobs': [{u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-28ecc05f-2cc4-43b7-ad04-cdd8a4ff3664/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-28ecc05f-2cc4-43b7-ad04-cdd8a4ff3664/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-28ecc05f-2cc4-43b7-ad04-cdd8a4ff3664/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-28ecc05f-2cc4-43b7-ad04-cdd8a4ff3664',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u\"Job failed; details available in '//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-28ecc05f-2cc4-43b7-ad04-cdd8a4ff3664/bytestreams/stdout'\",\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-22T20:29:16.141Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-22T20:12:53.737Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-22T20:12:54.420Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-22T20:13:09.003Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-d9ffdfd1-8b8e-4d0d-b18b-f9ffe2ab338d/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-d9ffdfd1-8b8e-4d0d-b18b-f9ffe2ab338d/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-d9ffdfd1-8b8e-4d0d-b18b-f9ffe2ab338d/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-d9ffdfd1-8b8e-4d0d-b18b-f9ffe2ab338d',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-18T20:15:09.496Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T20:07:58.905Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-18T20:07:59.147Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-18T20:08:05.775Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T20:14:27.308Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-18T20:14:48.625Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-c068d703-9ea0-45b2-b35b-0cee7dc00f3f/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-c068d703-9ea0-45b2-b35b-0cee7dc00f3f/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-c068d703-9ea0-45b2-b35b-0cee7dc00f3f/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-c068d703-9ea0-45b2-b35b-0cee7dc00f3f',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u\"Job failed; details available in '//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-c068d703-9ea0-45b2-b35b-0cee7dc00f3f/bytestreams/stdout'\",\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-18T19:45:20.385Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T19:29:30.810Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-18T19:29:31.799Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-18T19:30:07.574Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-5a3c71d0-5aa4-4db3-84a4-68604516bd27/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-5a3c71d0-5aa4-4db3-84a4-68604516bd27/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-5a3c71d0-5aa4-4db3-84a4-68604516bd27/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-5a3c71d0-5aa4-4db3-84a4-68604516bd27',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-18T19:30:43.407Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T18:49:48.333Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-18T18:49:48.607Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-18T18:50:16.520Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T19:29:19.606Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-18T19:29:45.964Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-7bcb85eb-36fe-4d0e-b30d-5a055b84c72c/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-7bcb85eb-36fe-4d0e-b30d-5a055b84c72c/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-7bcb85eb-36fe-4d0e-b30d-5a055b84c72c/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-7bcb85eb-36fe-4d0e-b30d-5a055b84c72c',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u\"Job failed; details available in '//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-7bcb85eb-36fe-4d0e-b30d-5a055b84c72c/bytestreams/stdout'\",\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-18T19:02:50.246Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T18:46:32.789Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-18T18:46:34.000Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-18T18:46:59.841Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-f7cfb93d-a656-4854-8f9e-93119d5ad409/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-f7cfb93d-a656-4854-8f9e-93119d5ad409/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-f7cfb93d-a656-4854-8f9e-93119d5ad409/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-f7cfb93d-a656-4854-8f9e-93119d5ad409',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-18T18:47:04.432Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-17T23:38:20.878Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-17T23:38:21.064Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-17T23:38:50.294Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-18T18:46:21.751Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-18T18:46:48.451Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-b6a9d2b6-bfa1-4422-a30c-8da95faa4ecb/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-b6a9d2b6-bfa1-4422-a30c-8da95faa4ecb/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-b6a9d2b6-bfa1-4422-a30c-8da95faa4ecb/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-b6a9d2b6-bfa1-4422-a30c-8da95faa4ecb',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u\"Job failed; details available in '//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-b6a9d2b6-bfa1-4422-a30c-8da95faa4ecb/bytestreams/stdout'\",\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-17T23:33:26.825Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-17T23:20:07.347Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-17T23:20:07.887Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-17T23:20:24.796Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-a822b38e-0a00-4949-ae5d-b76648fcadaa/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-a822b38e-0a00-4949-ae5d-b76648fcadaa/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-a822b38e-0a00-4949-ae5d-b76648fcadaa/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-a822b38e-0a00-4949-ae5d-b76648fcadaa',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-17T23:17:49.330Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-16T04:28:53.561Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-16T04:28:53.810Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-16T04:29:06.806Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-17T23:17:25.350Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-17T23:17:32.183Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-4fa4f1e0-05e7-42cc-86d1-68cd0da95b5f/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-4fa4f1e0-05e7-42cc-86d1-68cd0da95b5f/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-4fa4f1e0-05e7-42cc-86d1-68cd0da95b5f/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-4fa4f1e0-05e7-42cc-86d1-68cd0da95b5f',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u\"Job failed; details available in '//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-4fa4f1e0-05e7-42cc-86d1-68cd0da95b5f/bytestreams/stdout'\",\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-16T04:26:06.858Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-16T04:19:15.071Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-16T04:19:15.710Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-16T04:19:41.443Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-92ec3127-5254-40d0-aaf6-077c3833e906/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-92ec3127-5254-40d0-aaf6-077c3833e906/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-92ec3127-5254-40d0-aaf6-077c3833e906/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-92ec3127-5254-40d0-aaf6-077c3833e906',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-16T04:10:32.943Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-09T04:08:52.618Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-09T04:08:52.908Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-09T04:08:59.275Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-16T04:10:16.523Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-16T04:10:26.891Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-be7d5a7d-1769-480a-8400-61d79b30df6a/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-be7d5a7d-1769-480a-8400-61d79b30df6a/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-be7d5a7d-1769-480a-8400-61d79b30df6a/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-be7d5a7d-1769-480a-8400-61d79b30df6a',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-09T04:08:30.466Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-09T04:04:57.117Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-09T04:04:57.314Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-09T04:05:07.548Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-09T04:07:27.351Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-09T04:07:40.879Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-df1d0b8a-1a7b-4004-a9d0-018a6992da83/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-df1d0b8a-1a7b-4004-a9d0-018a6992da83/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/39d18ff1-db0d-4305-bfb1-66dfd69e5758/jobs/spark-shell-df1d0b8a-1a7b-4004-a9d0-018a6992da83/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'39d18ff1-db0d-4305-bfb1-66dfd69e5758'},\n",
       "   u'reference': {u'jobId': u'spark-shell-df1d0b8a-1a7b-4004-a9d0-018a6992da83',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-09T04:05:01.463Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-09T03:43:06.974Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-09T03:43:07.306Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-09T03:43:14.273Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-09T04:04:46.201Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-09T04:04:55.687Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-e8c4e86b-5ae2-4ed2-b759-ff795b191444/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-e8c4e86b-5ae2-4ed2-b759-ff795b191444/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-e8c4e86b-5ae2-4ed2-b759-ff795b191444/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'74aa2106-8f97-472e-a593-2b675af68b6a'},\n",
       "   u'reference': {u'jobId': u'spark-shell-e8c4e86b-5ae2-4ed2-b759-ff795b191444',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u'Task was cancelled.',\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-12-09T03:40:17.711Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:26:15.465Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-05T00:26:15.693Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-05T00:26:21.722Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-9349b56f-34a8-4709-9dfa-d048c8d31bf3/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-9349b56f-34a8-4709-9dfa-d048c8d31bf3/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-9349b56f-34a8-4709-9dfa-d048c8d31bf3/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'74aa2106-8f97-472e-a593-2b675af68b6a'},\n",
       "   u'reference': {u'jobId': u'spark-shell-9349b56f-34a8-4709-9dfa-d048c8d31bf3',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-05T00:33:32.621Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:25:31.911Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-05T00:25:32.109Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-05T00:25:41.487Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:33:06.531Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-05T00:33:17.538Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-b3c1f038-e564-4561-910e-fd39df314798/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-b3c1f038-e564-4561-910e-fd39df314798/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-b3c1f038-e564-4561-910e-fd39df314798/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'74aa2106-8f97-472e-a593-2b675af68b6a'},\n",
       "   u'reference': {u'jobId': u'spark-shell-b3c1f038-e564-4561-910e-fd39df314798',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-05T00:34:27.846Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:24:50.571Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-05T00:24:50.811Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-05T00:25:02.627Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:33:22.646Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-05T00:34:04.749Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-eb1a2cfe-a8da-4394-8106-b474bd412dbc/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-eb1a2cfe-a8da-4394-8106-b474bd412dbc/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/74aa2106-8f97-472e-a593-2b675af68b6a/jobs/spark-shell-eb1a2cfe-a8da-4394-8106-b474bd412dbc/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'74aa2106-8f97-472e-a593-2b675af68b6a'},\n",
       "   u'reference': {u'jobId': u'spark-shell-eb1a2cfe-a8da-4394-8106-b474bd412dbc',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'state': u'CANCELLED',\n",
       "    u'stateStartTime': u'2015-12-05T00:34:26.438Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-12-04T20:06:11.240Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-12-04T20:06:11.587Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-12-04T20:06:21.989Z'},\n",
       "    {u'state': u'CANCEL_PENDING',\n",
       "     u'stateStartTime': u'2015-12-05T00:33:34.430Z'},\n",
       "    {u'details': u'Agent reported job failure',\n",
       "     u'state': u'CANCEL_STARTED',\n",
       "     u'stateStartTime': u'2015-12-05T00:33:49.863Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-86a07d5c-8c32-44c4-ae56-35b4c1096347/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-86a07d5c-8c32-44c4-ae56-35b4c1096347/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-86a07d5c-8c32-44c4-ae56-35b4c1096347/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1'},\n",
       "   u'reference': {u'jobId': u'spark-shell-86a07d5c-8c32-44c4-ae56-35b4c1096347',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u'Task was cancelled.',\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-11-26T00:16:26.397Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-11-26T00:08:20.593Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-11-26T00:08:20.861Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-11-26T00:08:26.186Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-1309e13c-e59a-45ac-a38d-39e7137ad54e/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-1309e13c-e59a-45ac-a38d-39e7137ad54e/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1/jobs/spark-shell-1309e13c-e59a-45ac-a38d-39e7137ad54e/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'617b4f4c-e48a-4a66-bfb2-430ba8cbcbd1'},\n",
       "   u'reference': {u'jobId': u'spark-shell-1309e13c-e59a-45ac-a38d-39e7137ad54e',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u'Task was cancelled.',\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-11-26T00:16:22.685Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-11-26T00:02:16.691Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-11-26T00:02:17.280Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-11-26T00:02:22.523Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-c6940cf3-1b7b-4d56-ad9b-8eb8a3505e98/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-c6940cf3-1b7b-4d56-ad9b-8eb8a3505e98/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-c6940cf3-1b7b-4d56-ad9b-8eb8a3505e98/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'0e18e110-3a94-4bf0-8651-8d79f90d4ae1'},\n",
       "   u'reference': {u'jobId': u'spark-shell-c6940cf3-1b7b-4d56-ad9b-8eb8a3505e98',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u'Task was cancelled.',\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-11-25T23:57:20.471Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-11-25T23:51:08.988Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-11-25T23:51:09.264Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-11-25T23:51:20.287Z'}]},\n",
       "  {u'driverControlFilesUri': u'gs://dataproc-9c5a7adf-7cdb-4eb2-b42d-d81754653069-us/google-cloud-dataproc-metainfo/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-af165cb1-63dc-4e3f-ae58-5054bcf84b26/',\n",
       "   u'driverInputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-af165cb1-63dc-4e3f-ae58-5054bcf84b26/bytestreams/stdin',\n",
       "   u'driverOutputResourceUri': u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/0e18e110-3a94-4bf0-8651-8d79f90d4ae1/jobs/spark-shell-af165cb1-63dc-4e3f-ae58-5054bcf84b26/bytestreams/stdout',\n",
       "   u'interactive': True,\n",
       "   u'placement': {u'clusterName': u'alekseyv-interact',\n",
       "    u'clusterUuid': u'0e18e110-3a94-4bf0-8651-8d79f90d4ae1'},\n",
       "   u'reference': {u'jobId': u'spark-shell-af165cb1-63dc-4e3f-ae58-5054bcf84b26',\n",
       "    u'projectId': u'datalab-spark'},\n",
       "   u'sparkJob': {u'loggingConfiguration': {},\n",
       "    u'mainClass': u'org.apache.spark.repl.Main'},\n",
       "   u'status': {u'details': u'Task was cancelled.',\n",
       "    u'state': u'ERROR',\n",
       "    u'stateStartTime': u'2015-11-25T23:57:18.949Z'},\n",
       "   u'statusHistory': [{u'state': u'PENDING',\n",
       "     u'stateStartTime': u'2015-11-25T22:57:13.062Z'},\n",
       "    {u'state': u'SETUP_DONE', u'stateStartTime': u'2015-11-25T22:57:13.349Z'},\n",
       "    {u'state': u'RUNNING', u'stateStartTime': u'2015-11-25T22:57:18.737Z'}]}],\n",
       " u'nextPageToken': u'CjBzcGFyay1zaGVsbC1hZjE2NWNiMS02M2RjLTRlM2YtYWU1OC01MDU0YmNmODRiMjYSBgjJ+diyBQ=='}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List jobs\n",
    "\n",
    "jobs_list(gcp.Context.default())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submit interactive job\n",
    "\n",
    "data = {\n",
    "  \"job\": {\n",
    "    \"placement\": {\n",
    "      \"clusterName\": \"alekseyv-interact\"\n",
    "    },\n",
    "    \"reference\": {\n",
    "      \"jobId\": \"alekseyv-manual-004c2b1a-12bb-45fe-b2b9-a140851bc8db\",\n",
    "      \"projectId\": \"datalab-spark\"\n",
    "    },\n",
    "    \"interactive\": \"True\",\n",
    "    \"sparkJob\": {\n",
    "      \"mainClass\": \"org.apache.spark.repl.Main\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "import gcp\n",
    "import gcp._context\n",
    "import gcp._util\n",
    "import gcp._util._http\n",
    "\n",
    "#                   https://dataproc.googleapis.com/v1beta1/projects/datalab-spark/jobs:submit\n",
    "url = 'https://test-dataproc.sandbox.googleapis.com/v1beta1/projects/datalab-spark/jobs:submit/'\n",
    "\n",
    "context = gcp.Context.default()\n",
    "response = gcp._util._http.Http.request(url, data=str(data), credentials=gcp.Context.default().credentials)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get interactive job details\n",
    "\n",
    "job_id = \"alekseyv-manual-004c2b1a-12bb-45fe-b2b9-a140851bc8da\"\n",
    "\n",
    "url = 'https://test-dataproc.sandbox.googleapis.com/v1beta1/projects/datalab-spark/jobs/' + job_id\n",
    "\n",
    "context = gcp.Context.default()\n",
    "job_details_response = gcp._util.Http.request(url, '', credentials=gcp.Context.default().credentials)  \n",
    "job_details_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gcp.Context.default().credentials.refresh(None)\n",
    "gcp.Context._global_context = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls /etc/ssl/certs/ca-*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gcp\n",
    "import gcp._context\n",
    "import gcp._util\n",
    "\n",
    "import sys\n",
    "import grpc.framework.face.exceptions\n",
    "from grpc.beta import implementations\n",
    "from gcp.spark.bytestream_pb2 import beta_create_ByteStream_stub\n",
    "from gcp.spark.bytestream_pb2 import ReadRequest\n",
    "from gcp.spark.bytestream_pb2 import ReadResponse\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from grpc.beta.implementations import ClientCredentials\n",
    "\n",
    "class MetadataTransformer(object):\n",
    "    \"\"\"Callable class to transform metadata for gRPC requests.\n",
    "    :type client: :class:`.client.Client`\n",
    "    :param client: The client that owns the cluster. Provides authorization and\n",
    "                   user agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, client):\n",
    "        self._credentials = client.credentials\n",
    "        self._user_agent = 'GoogleCloudDataLab/1.0'\n",
    "\n",
    "    def __call__(self, ignored_val):\n",
    "        \"\"\"Adds authorization header to request metadata.\"\"\"\n",
    "        access_token = self._credentials.get_access_token().access_token\n",
    "        print(access_token)\n",
    "        return [\n",
    "            ('Authorization', 'Bearer ' + access_token),\n",
    "            ('User-agent', self._user_agent),\n",
    "        ]\n",
    "\n",
    "SSL_CERT_FILE = '/etc/ssl/certs/ca-certificates.crt'\n",
    "def get_certs():\n",
    "    \"\"\"Gets the root certificates.\n",
    "    .. note::\n",
    "        This is only called by :func:`make_stub`. For most applications,\n",
    "        a few gRPC stubs (four total, one for each service) will be created\n",
    "        when a :class:`.Client` is created. This function will not likely\n",
    "        be used again while that application is running.\n",
    "        However, it may be worthwhile to cache the output of this function.\n",
    "    :rtype: str\n",
    "    :returns: The root certificates for the current machine.\n",
    "    \"\"\"\n",
    "    with open(SSL_CERT_FILE, mode='rb') as file_obj:\n",
    "        return file_obj.read()\n",
    "\n",
    "# refresh OAuth token\n",
    "#gcp.Context.default().credentials.refresh(None)\n",
    "#gcp.Context._global_context = None\n",
    "\n",
    "DEFAULT_HOST = \"test-dataproc.sandbox.googleapis.com\";\n",
    "DEFAULT_PORT = 443;\n",
    "\n",
    "JOB_ID = 'spark-shell-92ec3127-5254-40d0-aaf6-077c3833e906'\n",
    "CLUSTER_ID = '39d18ff1-db0d-4305-bfb1-66dfd69e5758'\n",
    "\n",
    "driverInputResourceUri = u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/%s/jobs/%s/bytestreams/stdin' % (CLUSTER_ID, JOB_ID)\n",
    "driverOutputResourceUri = u'//test-dataproc.sandbox.googleapis.com/projects/datalab-spark/clusters/%s/jobs/%s/bytestreams/stdout' % (CLUSTER_ID, JOB_ID)\n",
    "\n",
    "custom_metadata_transformer = MetadataTransformer(gcp.Context.default())\n",
    "\n",
    "root_certificates = get_certs()\n",
    "client_credentials = implementations.ssl_client_credentials(root_certificates, private_key=None, certificate_chain=None)\n",
    "\n",
    "try:\n",
    "  channel = implementations.secure_channel(DEFAULT_HOST, DEFAULT_PORT, client_credentials)\n",
    "  stub = beta_create_ByteStream_stub(channel, metadata_transformer=custom_metadata_transformer)\n",
    "  readRequest = ReadRequest(resource_name=driverOutputResourceUri, read_limit=1024, read_offset=2900)\n",
    "\n",
    "  response = stub.Read(readRequest, 10)\n",
    "  print('response: %s' % response.result())\n",
    "except grpc.framework.interfaces.face.face.ExpirationError as ex:\n",
    "  print('expiration error: ex.code:%s, ex.details:%s' % (ex.code, ex.details))\n",
    "except grpc.framework.interfaces.face.face.NetworkError as ex:\n",
    "  print('expiration error: ex.code:%s, ex.details:%s' % (ex.code, ex.details))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
